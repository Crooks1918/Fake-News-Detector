{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bd975f-d57c-4655-a64c-55e900c8451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fc20db-2781-4f55-9409-b7e27126d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"/Users/rhyscrooks/Desktop/Uni/4th_Year/Current Topics/fake_or_real_news.csv\")\n",
    "if 'Unnamed: 0' in news.columns: \n",
    "    news = news.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e87a4d-906e-4127-aff9-f65e394800f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                 ...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f066f25-ddc3-4763-8bea-d10756908a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   title   6335 non-null   str  \n",
      " 1   text    6335 non-null   str  \n",
      " 2   label   6335 non-null   str  \n",
      "dtypes: str(3)\n",
      "memory usage: 29.3 MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a0f9d-62f8-49da-bba0-65b1ea9af711",
   "metadata": {},
   "source": [
    "No nulls so dont have to clean or remove anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e30f07c-e590-4245-97b1-6eb53f61b1ad",
   "metadata": {},
   "source": [
    "Create 3 models: \n",
    "- df1 = one with just title (can it predict real/fake from title alone)\n",
    "- df2 = one with just text (can it predict real/fake from text alone)\n",
    "- df3 = combined (can it predict real/fake from both title and text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c719366-e953-4c2b-a2c6-94fabfa60636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real articles: 3171\n",
      "Number of fake articles: 3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_count = news[news['label'] == 'FAKE']['label'].count()\n",
    "real_count = news[news['label'] == 'REAL']['label'].count()\n",
    "print(f'Number of real articles: {real_count}\\n' \n",
    "      f'Number of fake articles: {fake_count}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff52580-5757-4ae3-a380-00c473d9d56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualisation of real vs fake articles \n",
    "labels = [\"Real\", \"Fake\"]\n",
    "counts = [real_count, fake_count]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(counts, labels=labels, autopct=\"%1.1f%%\")\n",
    "plt.title(\"Distribution of Real vs Fake Articles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074591c1-4552-43e5-b07b-8aaa7d17b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['label'] = news['label'].replace('FAKE', 'fake')\n",
    "news['label'] = news['label'].replace('REAL', 'real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d9b928-c232-48d8-beaa-776f941d3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = news.copy() \n",
    "df2 = news.copy() \n",
    "df3 = news.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c8f89-51ef-423c-8a5f-75583be8bc91",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f9d31d-13e9-4377-a6c3-0fd71cc13791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation function \n",
    "\n",
    "def normalise_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower() # convert to lower case\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove special characters and punctuation\n",
    "    text = text.strip() # strip whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text) # collapses multiple spaces\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply to specific columns\n",
    "df1['title'] = df1['title'].apply(normalise_text) \n",
    "df2['text'] = df2['text'].apply(normalise_text)\n",
    "df3['title'] = df1['title'].apply(normalise_text) \n",
    "df3['text'] = df2['text'].apply(normalise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6180f8ab-c079-4bdc-837d-e00568098a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhyscrooks/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# lematisation \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatise(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df1['title'] = df1['title'].apply(lemmatise)\n",
    "df2['text']  = df2['text'].apply(lemmatise)\n",
    "df3['title'] = df3['title'].apply(lemmatise)\n",
    "df3['text']  = df3['text'].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241ae8c-5c78-4e4a-a82c-00b7c84c87ca",
   "metadata": {},
   "source": [
    "## Processing to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "902a7d6d-bf75-45e0-8538-fd11a547e562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "# Converting to vectors \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "df1_tokens = df1['title'].apply(lambda x: x.split())\n",
    "df2_tokens = df2['text'].apply(lambda x: x.split())\n",
    "df3_title_tokens = df3['title'].apply(lambda x: x.split())\n",
    "df3_text_tokens = df3['text'].apply(lambda x: x.split())\n",
    "df3_tokens = df3_title_tokens + df3_text_tokens\n",
    "\n",
    "# Train Word2Vec model\n",
    "model1 = Word2Vec(sentences=df1_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model2 = Word2Vec(sentences=df2_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model3 = Word2Vec(sentences=df3_tokens, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5220e7c2-64f3-48f3-875d-164d3a6eefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document level vecors \n",
    "\n",
    "def get_doc_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df1['vector'] = df1_tokens.apply(lambda x: get_doc_vector(x, model1))\n",
    "df2['vector'] = df2_tokens.apply(lambda x: get_doc_vector(x, model2))\n",
    "df3['vector'] = df3_tokens.apply(lambda x: get_doc_vector(x, model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9f25650-0b49-4fe6-b265-c25b053b426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecoding labels \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df1['label_encoded'] = le.fit_transform(df1['label'])\n",
    "df2['label_encoded'] = le.fit_transform(df2['label'])\n",
    "df3['label_encoded'] = le.fit_transform(df3['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b96a1a-5e2a-4e3d-b4db-4330a1e74220",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0ee07cb-96c4-4a19-a071-4f737c72f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert vector columns to 2D arrays\n",
    "X1 = np.stack(df1['vector'].values)\n",
    "X2 = np.stack(df2['vector'].values)\n",
    "X3 = np.stack(df3['vector'].values)\n",
    "\n",
    "y1 = df1['label_encoded']\n",
    "y2 = df2['label_encoded']\n",
    "y3 = df3['label_encoded']\n",
    "\n",
    "# Train/test split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e9177-1443-4363-89c4-7bfd2b08246a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a00181ed-093d-4d62-934e-774e698c92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 (title only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.57      0.58      0.57       628\n",
      "        real       0.58      0.56      0.57       639\n",
      "\n",
      "    accuracy                           0.57      1267\n",
      "   macro avg       0.57      0.57      0.57      1267\n",
      "weighted avg       0.57      0.57      0.57      1267\n",
      "\n",
      "df2 (text only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.89      0.87      0.88       628\n",
      "        real       0.87      0.89      0.88       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "df3 (combined):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.89      0.88      0.89       628\n",
      "        real       0.89      0.89      0.89       639\n",
      "\n",
      "    accuracy                           0.89      1267\n",
      "   macro avg       0.89      0.89      0.89      1267\n",
      "weighted avg       0.89      0.89      0.89      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# modelling - logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialise the model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# df1 - title only\n",
    "lr.fit(X1_train, y1_train)\n",
    "y1_pred = lr.predict(X1_test)\n",
    "print(\"df1 (title only):\")\n",
    "print(classification_report(y1_test, y1_pred, target_names=['fake', 'real']))\n",
    "\n",
    "# df2 - text only\n",
    "lr.fit(X2_train, y2_train)\n",
    "y2_pred = lr.predict(X2_test)\n",
    "print(\"df2 (text only):\")\n",
    "print(classification_report(y2_test, y2_pred, target_names=['fake', 'real']))\n",
    "\n",
    "# df3 - combined\n",
    "lr.fit(X3_train, y3_train)\n",
    "y3_pred = lr.predict(X3_test)\n",
    "print(\"df3 (combined):\")\n",
    "print(classification_report(y3_test, y3_pred, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6230a2f-fc24-4d49-8e7a-32ef2d130eac",
   "metadata": {},
   "source": [
    "#### Interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2bb0e6-f892-42f1-bf0b-bb8223f9750c",
   "metadata": {},
   "source": [
    "**Title Only**\n",
    "\n",
    "Poor result with only 57% accuracy, which is only 7% better than guessing. This model and method is struggling with both classes (real/fake). From these results we can see that from the title alone it is difficult to classify between real and fake with accuracy. This could be due to the preprocessing steps that likely reduce the sensationalism generally seen within fake articles. \n",
    "\n",
    "**Text Only** \n",
    "\n",
    "A significant increase in performance identifying 88% percent of articles with a balanced performance across both classes. This is to be expected becuase 'text' encompasses far more linguistic signals that can distinguish fake and real news, such as writing style, sources cited, emotional language, and factual claims. This model catches 87% of fake articles and is right 89% of the time. \n",
    "\n",
    "**Combined** \n",
    "\n",
    "A marginal imporvement increasing by just 1% suggesting that infromation encoded within the title is worht 1%. The model is already extracting most of the useful signal from the body text alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81c919-8b56-4996-bdd6-1e472994e4ec",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6eb6c7fa-986d-493a-aff1-56aa9c5a00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 (title only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.62      0.65      0.63       628\n",
      "        real       0.64      0.60      0.62       639\n",
      "\n",
      "    accuracy                           0.63      1267\n",
      "   macro avg       0.63      0.63      0.63      1267\n",
      "weighted avg       0.63      0.63      0.63      1267\n",
      "\n",
      "df2 (text only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.88      0.91      0.89       628\n",
      "        real       0.91      0.87      0.89       639\n",
      "\n",
      "    accuracy                           0.89      1267\n",
      "   macro avg       0.89      0.89      0.89      1267\n",
      "weighted avg       0.89      0.89      0.89      1267\n",
      "\n",
      "df3 (combined):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.87      0.90      0.89       628\n",
      "        real       0.90      0.87      0.88       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.89      0.88      0.88      1267\n",
      "weighted avg       0.89      0.88      0.88      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# df1 - title only\n",
    "rf.fit(X1_train, y1_train)\n",
    "y1_pred_rf = rf.predict(X1_test)\n",
    "print(\"df1 (title only):\")\n",
    "print(classification_report(y1_test, y1_pred_rf, target_names=['fake', 'real']))\n",
    "\n",
    "# df2 - text only\n",
    "rf.fit(X2_train, y2_train)\n",
    "y2_pred_rf = rf.predict(X2_test)\n",
    "print(\"df2 (text only):\")\n",
    "print(classification_report(y2_test, y2_pred_rf, target_names=['fake', 'real']))\n",
    "\n",
    "# df3 - combined\n",
    "rf.fit(X3_train, y3_train)\n",
    "y3_pred_rf = rf.predict(X3_test)\n",
    "print(\"df3 (combined):\")\n",
    "print(classification_report(y3_test, y3_pred_rf, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5467668-aa99-4c91-9c03-fe3132ca4e57",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "\n",
    "**Title Only** \n",
    "\n",
    "An improvement compared to logistic regression model (63%) suggesting a random forest model is better at indetifying fake articles from the title alone. However it is still a poor score overall, supporting previous results which indicate title alone is an unreliable varaible. \n",
    "\n",
    "**Text Only** \n",
    "\n",
    "Matches Logistic Regression's performance on text. Interestingly the model is slightly better at catching fake articles (recall 0.91) than real ones (recall 0.87), meaning it's slightly more aggressive at flagging things as fake. This could be a concern in a real world system where you don't want to incorrectly flag real news as fake.\n",
    "\n",
    "**Combined** \n",
    "\n",
    "Surprisingly, the combined model performs slightly worse than text only (88% vs 89%). This is unusual and suggests that adding the title is actually introducing a little noise rather than helping. Random Forest may be getting confused by the extra title features that weren't useful in title only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04267bc-6fb5-4026-a5c1-f33f1848c406",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aec24d05-b17c-4514-ae70-dbe8d11ad447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 (title only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.57      0.52      0.54       628\n",
      "        real       0.57      0.62      0.59       639\n",
      "\n",
      "    accuracy                           0.57      1267\n",
      "   macro avg       0.57      0.57      0.57      1267\n",
      "weighted avg       0.57      0.57      0.57      1267\n",
      "\n",
      "df2 (text only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.90      0.88      0.89       628\n",
      "        real       0.88      0.90      0.89       639\n",
      "\n",
      "    accuracy                           0.89      1267\n",
      "   macro avg       0.89      0.89      0.89      1267\n",
      "weighted avg       0.89      0.89      0.89      1267\n",
      "\n",
      "df3 (combined):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.89      0.89      0.89       628\n",
      "        real       0.89      0.89      0.89       639\n",
      "\n",
      "    accuracy                           0.89      1267\n",
      "   macro avg       0.89      0.89      0.89      1267\n",
      "weighted avg       0.89      0.89      0.89      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# df1 - title only\n",
    "svm.fit(X1_train, y1_train)\n",
    "y1_pred_svm = svm.predict(X1_test)\n",
    "print(\"df1 (title only):\")\n",
    "print(classification_report(y1_test, y1_pred_svm, target_names=['fake', 'real']))\n",
    "\n",
    "# df2 - text only\n",
    "svm.fit(X2_train, y2_train)\n",
    "y2_pred_svm = svm.predict(X2_test)\n",
    "print(\"df2 (text only):\")\n",
    "print(classification_report(y2_test, y2_pred_svm, target_names=['fake', 'real']))\n",
    "\n",
    "# df3 - combined\n",
    "svm.fit(X3_train, y3_train)\n",
    "y3_pred_svm = svm.predict(X3_test)\n",
    "print(\"df3 (combined):\")\n",
    "print(classification_report(y3_test, y3_pred_svm, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5adc77-f607-49b0-b0db-0f080c32355e",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "\n",
    "**Title Only** \n",
    "\n",
    "Same as Logistic Regression and worse than Random Forest on titles. Interestingly there's a slight imbalance — the model is better at catching real articles (recall 0.62) than fake ones (recall 0.52), meaning it's slightly biased towards predicting real. Again this confirms titles alone are not sufficient regardless of model.\n",
    "\n",
    "**Text Only** \n",
    "\n",
    "Strong performance, matching Random Forest and just edging Logistic Regression. Notably the precision for fake is 0.90 — the highest fake precision across all three models — meaning SVM is the most trustworthy when it flags something as fake.\n",
    "\n",
    "**Combined** \n",
    "\n",
    "A perfectly balanced result with every single metric is 0.89 across both classes. This is the most consistent performance of any model on any dataframe, suggesting SVM handles the combined features the most cleanly. Going forward this will be the chosen model and inputs due to the reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b77ee3-54d2-4204-87dd-be93a03d7ee7",
   "metadata": {},
   "source": [
    "## Improvments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e1699-377b-446c-b185-919658d05384",
   "metadata": {},
   "source": [
    "### Finding Optimal Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "362f846b-1d93-4e1a-83cc-4961c20ea777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 100, 'kernel': 'rbf'}\n",
      "Best score: 0.905687599665882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "grid = GridSearchCV(SVC(random_state=42), params, cv=5, scoring='accuracy')\n",
    "grid.fit(X3_train, y3_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a4d57a6-cf09-4146-be5f-089d3cb5435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.91      0.91       628\n",
      "        real       0.91      0.92      0.92       639\n",
      "\n",
      "    accuracy                           0.91      1267\n",
      "   macro avg       0.91      0.91      0.91      1267\n",
      "weighted avg       0.91      0.91      0.91      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid.best_estimator_\n",
    "\n",
    "y3_pred_best = best_svm.predict(X3_test)\n",
    "print(classification_report(y3_test, y3_pred_best, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4a8cf-44c4-4079-8b64-8bce5b344daa",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "\n",
    "Adjusting the parameters of the svm model increased the accuracy by 2% which is meaningful given the dataset size. With a cross validation score of 90.5% and test score of 91% indicates the model has generalised well to unseen data and is not overfitting. Furthermore precision and recall are almost identical across both classes (91%/92%), meaning the model isn't biased towards predicting fake or real. It's equally good at catching both which is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410f85c-57ea-432c-a710-aa1c8e799f6c",
   "metadata": {},
   "source": [
    "### Word2Vec Optimisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0273a879-37ae-4632-8359-d36b2cfd341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "# Increase vector size from 100 to 300\n",
    "model3 = Word2Vec(sentences=df3_tokens, vector_size=300, window=10, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2775241-8984-42ac-aebe-1e1714b890ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.91      0.91       628\n",
      "        real       0.91      0.92      0.92       639\n",
      "\n",
      "    accuracy                           0.91      1267\n",
      "   macro avg       0.91      0.91      0.91      1267\n",
      "weighted avg       0.91      0.91      0.91      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3['vector'] = df3_tokens.apply(lambda x: get_doc_vector(x, model3))\n",
    "\n",
    "X3 = np.stack(df3['vector'].values)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "best_svm = SVC(kernel='rbf', C=100, random_state=42)\n",
    "best_svm.fit(X3_train, y3_train)\n",
    "y3_pred = best_svm.predict(X3_test)\n",
    "print(classification_report(y3_test, y3_pred, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066740a6-6ee2-4fb5-8dc0-48d7386363b6",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The tuned SVM model with 300-dimensional Word2Vec vectors achieved an overall accuracy of 91% on the test set of 1,267 articles. The model performed consistently across both classes, achieving an F1-score of 0.91 for fake articles and 0.92 for real articles, indicating no significant bias towards either class. In terms of precision, the model correctly identified 92% of articles it predicted as fake and 91% of articles it predicted as real. Recall was similarly strong, with the model successfully catching 91% of all truly fake articles and 92% of all truly real articles. The near identical macro and weighted averages of 0.91 across all metrics further confirm the model's balanced performance, which is particularly important in a fake news detection context where both missing fake articles and incorrectly flagging real ones carry real world consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d53ea0a-313d-41dd-a0d6-208de17d3ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.90      0.91      0.91       628\n",
      "        real       0.91      0.90      0.91       639\n",
      "\n",
      "    accuracy                           0.91      1267\n",
      "   macro avg       0.91      0.91      0.91      1267\n",
      "weighted avg       0.91      0.91      0.91      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# increasing vector size to 350 \n",
    "model3 = Word2Vec(sentences=df3_tokens, vector_size=350, window=10, min_count=1, workers=4)\n",
    "df3['vector'] = df3_tokens.apply(lambda x: get_doc_vector(x, model3))\n",
    "\n",
    "X3 = np.stack(df3['vector'].values)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "best_svm = SVC(kernel='rbf', C=100, random_state=42)\n",
    "best_svm.fit(X3_train, y3_train)\n",
    "y3_pred = best_svm.predict(X3_test)\n",
    "print(classification_report(y3_test, y3_pred, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544d4ac-5ad7-4b3d-ac47-d57abfde426d",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "\n",
    "A marginal decrease in performance indicating a dimension size of 300 perfroms better compared to 350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d338189-bff2-4c76-9482-3c5a0124ee65",
   "metadata": {},
   "source": [
    "### Removing stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03821383-71e6-4675-bcbf-431c6b3b1680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhyscrooks/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rhyscrooks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.91      0.91       628\n",
      "        real       0.91      0.92      0.91       639\n",
      "\n",
      "    accuracy                           0.91      1267\n",
      "   macro avg       0.91      0.91      0.91      1267\n",
      "weighted avg       0.91      0.91      0.91      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatise(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "\n",
    "df3['title'] = df3['title'].apply(lemmatise)\n",
    "df3['text']  = df3['text'].apply(lemmatise)\n",
    "\n",
    "df3_title_tokens = df3['title'].apply(lambda x: x.split())\n",
    "df3_text_tokens = df3['text'].apply(lambda x: x.split())\n",
    "df3_tokens = df3_title_tokens + df3_text_tokens\n",
    "\n",
    "# Train Word2Vec model\n",
    "model3 = Word2Vec(sentences=df3_tokens, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "df3['vector'] = df3_tokens.apply(lambda x: get_doc_vector(x, model3))\n",
    "\n",
    "X3 = np.stack(df3['vector'].values)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "best_svm = SVC(kernel='rbf', C=100, random_state=42)\n",
    "best_svm.fit(X3_train, y3_train)\n",
    "y3_pred = best_svm.predict(X3_test)\n",
    "print(classification_report(y3_test, y3_pred, target_names=['fake', 'real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a72505-f2a8-4560-aaf4-5dcb5bc2e46a",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "\n",
    "A slight drop in perfromance when removing stopwords. This suggests words like \"the\", \"is\", \"and\" actually help and improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ab404-2b64-4aa7-97cf-93ce19e537ec",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "This project aimed to build a fake news detector using a dataset of 6,335 news articles, equally split between fake and real. Three versions of the dataset were created with title only (df1), text only (df2), and combined title and text (df3). This enabled me to investigate which features were most useful for classification. Text was preprocessed through normalisation and lemmatisation before being converted to numerical vectors using Word2Vec.\n",
    "\n",
    "Three classifiers were evaluated; Logistic Regression, Random Forest, and SVM. Title only models performed poorly across all classifiers, peaking at 63% with Random Forest, suggesting article headlines alone do not contain enough information to reliably detect fake news. Text only and combined models performed significantly better, with most achieving around 88-89% accuracy.\n",
    "\n",
    "The best performing model was a tuned SVM using RBF kernel with C=100, trained on 300-dimensional Word2Vec vectors of the combined title and text features, achieving 91% accuracy with balanced precision and recall across both classes. Hyperparameter tuning via GridSearchCV and increasing Word2Vec vector size from 100 to 300 dimensions were the two most impactful improvements. Stopword removal and increasing vector size beyond 300 dimensions both slightly decreased performance, suggesting the model had reached its optimal configuration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
